import json;
# ==================== New Functions for API-like Interaction ====================

# Global cache for video lookup (build once if videos list doesn't change)
_video_lookup_cache = None

def _build_video_lookup(videos):
    """Helper to build a URL-to-Video object mapping."""
    global _video_lookup_cache
    if _video_lookup_cache is None:
        print("Building video lookup cache...")
        _video_lookup_cache = {v.url: v for v in videos if v.url != "N/A"}
        print(f"Video lookup cache built with {len(_video_lookup_cache)} entries.")
    return _video_lookup_cache

def get_user_history(user_index, users, videos, history_type='watched'):
    """
    Returns a user's watch or like history in JSON format.

    Args:
        user_index (int): The index of the user in the 'users' list (0 to NUM_USERS-1).
        users (list): The list of User objects.
        videos (list): The list of Video objects.
        history_type (str): 'watched' or 'liked' to specify which history to return.

    Returns:
        str: A JSON string representing a list of video details
             [{"id": video_url, "title": video_title, "cover": cover_url}, ...],
             or a JSON object with an error message if inputs are invalid.
    """
    # --- Input Validation ---
    if not isinstance(user_index, int) or user_index < 0 or user_index >= len(users):
        return json.dumps({"error": f"Invalid user_index: {user_index}. Must be between 0 and {len(users)-1}."})
    if history_type not in ['watched', 'liked']:
        return json.dumps({"error": f"Invalid history_type: {history_type}. Must be 'watched' or 'liked'."})

    # --- Data Retrieval ---
    try:
        target_user = users[user_index]
        video_lookup = _build_video_lookup(videos) # Use helper to build/get cache

        if history_type == 'watched':
            history_list = target_user.watched_videos
        else: # history_type == 'liked'
            history_list = target_user.liked_videos

        # --- Format Output ---
        output_list = []
        # Use a set to avoid duplicate video entries if a user watched/liked the same video multiple times
        seen_urls = set()
        # Iterate in reverse to get most recent first (optional)
        for url, timestamp in reversed(history_list):
            if url in video_lookup and url not in seen_urls:
                video = video_lookup[url]
                output_list.append({
                    "id": video.url,
                    # Provide defaults if title/cover are None
                    "title": video.title if video.title else "N/A",
                    "cover": video.cover_url if video.cover_url else "N/A"
                })
                seen_urls.add(url)
            # Optional: Add handling for URLs in history but not in video_lookup (data inconsistency)
            # else:
            #    print(f"Warning: Video URL '{url}' from user {target_user.user_id}'s history not found in video data.")

        return json.dumps(output_list, indent=4, ensure_ascii=False) # ensure_ascii=False for non-ASCII titles

    except Exception as e:
        return json.dumps({"error": f"An unexpected error occurred: {str(e)}"})


# Global variable to store user clustering results after generation
_user_clusters_df = None

def get_similar_users(user_index, users, user_clusters_df, top_n=10):
    """
    Finds users similar to the target user based on pre-computed clustering.

    Args:
        user_index (int): The index of the target user in the 'users' list.
        users (list): The list of User objects.
        user_clusters_df (pd.DataFrame): DataFrame generated by user_clustering,
                                         containing at least '用户ID' and '聚类ID' columns.
        top_n (int): The maximum number of similar user IDs to return.

    Returns:
        str: A JSON string representing a list of similar user IDs [{"id": user_id}, ...],
             or a JSON object with an error message.
    """
    # --- Input Validation ---
    if not isinstance(user_index, int) or user_index < 0 or user_index >= len(users):
        return json.dumps({"error": f"Invalid user_index: {user_index}. Must be between 0 and {len(users)-1}."})
    if user_clusters_df is None or user_clusters_df.empty:
        return json.dumps({"error": "User clustering data is not available or empty."})
    if not all(col in user_clusters_df.columns for col in ['用户ID', '聚类ID']):
         return json.dumps({"error": "User clustering DataFrame is missing required columns ('用户ID', '聚类ID')."})

    # --- Find Similar Users ---
    try:
        target_user = users[user_index]
        target_user_id = target_user.user_id

        # Find the cluster ID of the target user
        target_cluster_rows = user_clusters_df[user_clusters_df['用户ID'] == target_user_id]

        if target_cluster_rows.empty:
            return json.dumps({"error": f"Target user {target_user_id} not found in clustering results."})

        # Handle potential multiple rows for the same user (shouldn't happen, but safe)
        target_cluster_id = target_cluster_rows['聚类ID'].iloc[0]

        # Find all users in the same cluster, excluding the target user
        similar_users_ids = user_clusters_df[
            (user_clusters_df['聚类ID'] == target_cluster_id) &
            (user_clusters_df['用户ID'] != target_user_id)
        ]['用户ID'].tolist()

        # --- Format Output ---
        # Return top_n users (the order within the cluster isn't ranked by similarity score here)
        output_list = [{"id": user_id} for user_id in similar_users_ids[:top_n]]

        return json.dumps(output_list, indent=4, ensure_ascii=False)

    except Exception as e:
        # Log the detailed error for debugging if needed
        # print(f"Error in get_similar_users: {e}")
        # traceback.print_exc()
        return json.dumps({"error": f"An unexpected error occurred while finding similar users: {str(e)}"})

# ============================================================================
